---
layout:     post
title:      卷积网络基本原理
subtitle:   卷积网络基本原理
date:       2017-10-05
author:     HR
header-img: img/post-bg-deeplearn.png
catalog: true
tags:
    - 深度学习
    - 神经网络
    - CNN

---


### 卷积网络概述 

卷积神经网络（Convolutional Neural Network,CNN）是一种前馈神经网络，它的人工神经元可以响应一部分覆盖范围内的周围单元，对于大型图像处理有出色表现。它包括卷积层(alternating convolutional layer)和池层(pooling layer)。

 
### 卷积网络的结构

![](https://raw.githubusercontent.com/hipsonlee/hipsonlee.github.io/master/img/post-bg-cnn.jpg)

  最左边：

是数据输入层，对数据做一些处理，比如去均值（把输入数据各个维度都中心化为0，避免数据过多偏差，影响训练效果）、归一化（把所有的数据都归一到同样的范围）、PCA/白化等等。CNN只对训练集做“去均值”这一步。

  中间是：

CONV：卷积计算层，线性乘积 求和。
RELU：激励层，上文2.2节中有提到：ReLU是激活函数的一种。
POOL：池化层，简言之，即取区域平均或最大。
   
 最右边是：

FC：全连接层
## CNN之卷积计算层
### 什么是卷积
首先，我们来了解下什么是卷积操作。
    对图像（不同的数据窗口数据）和滤波矩阵（一组固定的权重：因为每个神经元的权重固定，所以又可以看做一个恒定的滤波器filter）做内积（逐个元素相乘再求和）的操作就是所谓的『卷积』操作，也是卷积神经网络的名字来源。
    比如下图中，图中左边部分是原始输入数据，图中中间部分是滤波器filter，图中右边是输出的新的二维数据。
 ![](http://img.blog.csdn.net/20160702215705128)

### 动态卷积图 

![](https://cs231n.github.io/assets/conv-demo/index.html)

随着左边数据窗口的平移滑动，滤波器Filter w0对不同的局部数据进行卷积计算。
    值得一提的是：
左边数据在变化，每次滤波器都是针对某一局部的数据窗口进行卷积，这就是所谓的CNN中的局部感知机制。
与此同时，数据窗口滑动，但中间滤波器Filter w0的权重（即每个神经元连接数据窗口的的权重）是固定不变的，这个权重不变即所谓的CNN中的参数共享机制。
    我第一次看到上面这个动态图的时候，只觉得很炫，另外就是据说“相乘后想加”，但到底具体是个怎么相乘后想加的过程 则无法一眼看出，网上也没有一目了然的计算过程。本文来细究下。
```


可以参考：[whats new in swift4](https://github.com/ole/whats-new-in-swift-4)


